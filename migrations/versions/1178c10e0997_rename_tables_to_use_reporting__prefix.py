"""Rename tables to use reporting_ prefix

Revision ID: 1178c10e0997
Revises: 801adf5bfe88
Create Date: 2025-06-23 15:24:23.157276

"""
from typing import Sequence, Union

from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision: str = '1178c10e0997'
down_revision: Union[str, None] = '801adf5bfe88'
branch_labels: Union[str, Sequence[str], None] = None
depends_on: Union[str, Sequence[str], None] = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('reporting_file_uploads',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('user_id', sa.UUID(), nullable=False),
    sa.Column('filename', sa.String(), nullable=False),
    sa.Column('original_filename', sa.String(), nullable=False),
    sa.Column('file_size', sa.Integer(), nullable=True),
    sa.Column('mime_type', sa.String(), nullable=True),
    sa.Column('file_extension', sa.String(), nullable=False),
    sa.Column('supabase_bucket', sa.String(), nullable=False),
    sa.Column('supabase_path', sa.String(), nullable=False),
    sa.Column('company_name', sa.String(), nullable=False),
    sa.Column('department', sa.String(), nullable=True),
    sa.Column('data_classification', sa.Enum('PORTFOLIO', 'OPERATIONS', 'PROJECT_MANAGEMENT', 'FINANCE', 'OTHER', name='dataclassification'), nullable=True),
    sa.Column('status', sa.Enum('UPLOADED', 'PROCESSING', 'COMPLETED', 'FAILED', name='filestatus'), nullable=False),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('processing_started_at', sa.DateTime(), nullable=True),
    sa.Column('processing_completed_at', sa.DateTime(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('updated_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('supabase_path')
    )
    op.create_table('reporting_analyses',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('file_id', sa.UUID(), nullable=False),
    sa.Column('agent_type', sa.Enum('EXCEL_ANALYZER', 'CHART_RECOMMENDER', 'DATA_CLASSIFIER', 'INSIGHT_GENERATOR', name='agenttype'), nullable=False),
    sa.Column('agent_version', sa.String(), nullable=False),
    sa.Column('parameters', sa.JSON(), nullable=True),
    sa.Column('status', sa.Enum('PENDING', 'IN_PROGRESS', 'COMPLETED', 'FAILED', 'CANCELLED', name='analysisstatus'), nullable=False),
    sa.Column('progress', sa.Float(), nullable=False),
    sa.Column('progress_message', sa.String(), nullable=True),
    sa.Column('error_message', sa.Text(), nullable=True),
    sa.Column('error_details', sa.JSON(), nullable=True),
    sa.Column('tokens_used', sa.Integer(), nullable=True),
    sa.Column('processing_time_seconds', sa.Float(), nullable=True),
    sa.Column('celery_task_id', sa.String(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.Column('started_at', sa.DateTime(), nullable=True),
    sa.Column('completed_at', sa.DateTime(), nullable=True),
    sa.ForeignKeyConstraint(['file_id'], ['reporting_file_uploads.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id'),
    sa.UniqueConstraint('celery_task_id')
    )
    op.create_table('reporting_results',
    sa.Column('id', sa.UUID(), nullable=False),
    sa.Column('analysis_id', sa.UUID(), nullable=False),
    sa.Column('result_type', sa.String(), nullable=False),
    sa.Column('title', sa.String(), nullable=False),
    sa.Column('description', sa.Text(), nullable=True),
    sa.Column('chart_type', sa.Enum('BAR', 'LINE', 'PIE', 'SCATTER', 'HEATMAP', 'TABLE', 'KPI', 'AREA', 'RADAR', 'TREEMAP', name='charttype'), nullable=True),
    sa.Column('chart_data', sa.JSON(), nullable=True),
    sa.Column('chart_config', sa.JSON(), nullable=True),
    sa.Column('insight_text', sa.Text(), nullable=True),
    sa.Column('confidence_score', sa.Float(), nullable=True),
    sa.Column('order_index', sa.Integer(), nullable=False),
    sa.Column('is_primary', sa.Boolean(), nullable=False),
    sa.Column('display_size', sa.String(), nullable=False),
    sa.Column('extra_metadata', sa.JSON(), nullable=True),
    sa.Column('created_at', sa.DateTime(), nullable=False),
    sa.ForeignKeyConstraint(['analysis_id'], ['reporting_analyses.id'], ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id')
    )
    op.drop_table('results')
    op.drop_table('analyses')
    op.drop_table('file_uploads')
    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    op.create_table('file_uploads',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('user_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('filename', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('original_filename', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('file_size', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('mime_type', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('file_extension', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('supabase_bucket', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('supabase_path', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('company_name', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('department', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('data_classification', postgresql.ENUM('PORTFOLIO', 'OPERATIONS', 'PROJECT_MANAGEMENT', 'FINANCE', 'OTHER', name='dataclassification'), autoincrement=False, nullable=True),
    sa.Column('status', postgresql.ENUM('UPLOADED', 'PROCESSING', 'COMPLETED', 'FAILED', name='filestatus'), autoincrement=False, nullable=False),
    sa.Column('error_message', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('processing_started_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('processing_completed_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('updated_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['user_id'], ['users.id'], name='file_uploads_user_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='file_uploads_pkey'),
    sa.UniqueConstraint('supabase_path', name='file_uploads_supabase_path_key'),
    postgresql_ignore_search_path=False
    )
    op.create_table('analyses',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('file_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('agent_type', postgresql.ENUM('EXCEL_ANALYZER', 'CHART_RECOMMENDER', 'DATA_CLASSIFIER', 'INSIGHT_GENERATOR', name='agenttype'), autoincrement=False, nullable=False),
    sa.Column('agent_version', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('parameters', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('status', postgresql.ENUM('PENDING', 'IN_PROGRESS', 'COMPLETED', 'FAILED', 'CANCELLED', name='analysisstatus'), autoincrement=False, nullable=False),
    sa.Column('progress', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=False),
    sa.Column('progress_message', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('error_message', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('error_details', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('tokens_used', sa.INTEGER(), autoincrement=False, nullable=True),
    sa.Column('processing_time_seconds', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('celery_task_id', sa.VARCHAR(), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.Column('started_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.Column('completed_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=True),
    sa.ForeignKeyConstraint(['file_id'], ['file_uploads.id'], name='analyses_file_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='analyses_pkey'),
    sa.UniqueConstraint('celery_task_id', name='analyses_celery_task_id_key'),
    postgresql_ignore_search_path=False
    )
    op.create_table('results',
    sa.Column('id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('analysis_id', sa.UUID(), autoincrement=False, nullable=False),
    sa.Column('result_type', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('title', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('description', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('chart_type', postgresql.ENUM('BAR', 'LINE', 'PIE', 'SCATTER', 'HEATMAP', 'TABLE', 'KPI', 'AREA', 'RADAR', 'TREEMAP', name='charttype'), autoincrement=False, nullable=True),
    sa.Column('chart_data', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('chart_config', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('insight_text', sa.TEXT(), autoincrement=False, nullable=True),
    sa.Column('confidence_score', sa.DOUBLE_PRECISION(precision=53), autoincrement=False, nullable=True),
    sa.Column('order_index', sa.INTEGER(), autoincrement=False, nullable=False),
    sa.Column('is_primary', sa.BOOLEAN(), autoincrement=False, nullable=False),
    sa.Column('display_size', sa.VARCHAR(), autoincrement=False, nullable=False),
    sa.Column('extra_metadata', postgresql.JSON(astext_type=sa.Text()), autoincrement=False, nullable=True),
    sa.Column('created_at', postgresql.TIMESTAMP(), autoincrement=False, nullable=False),
    sa.ForeignKeyConstraint(['analysis_id'], ['analyses.id'], name='results_analysis_id_fkey', ondelete='CASCADE'),
    sa.PrimaryKeyConstraint('id', name='results_pkey')
    )
    op.drop_table('reporting_results')
    op.drop_table('reporting_analyses')
    op.drop_table('reporting_file_uploads')
    # ### end Alembic commands ###